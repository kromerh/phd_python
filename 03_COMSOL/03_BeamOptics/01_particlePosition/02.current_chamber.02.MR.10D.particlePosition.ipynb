{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMSOL Study: Mesh refinement for current vacuum chamber\n",
    "## Emitting spot size on the target (last timestep)\n",
    "- current chamber\n",
    "- COMSOL files 02.MR.10D - current vacuum chamber with microwave ion source (1 mm aperture)\n",
    "- Mesh is mesh surface contraints\n",
    "- last accessed: 2019-02-06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import kde\n",
    "from scipy import optimize\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib import pyplot, transforms\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify path to datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = '02.current_chamber/02.MR/particleData/10D'\n",
    "\n",
    "remote_path = f'/Users/hkromer/02_PhD/02_Data/01_COMSOL/\\\n",
    "01_IonOptics/{foldername}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a tophat function\n",
    "def tophat(x, base_level, hat_level, hat_mid, hat_width):\n",
    "\treturn np.where((hat_mid - hat_width / 2. < x) &\n",
    "\t\t\t\t\t(x < hat_mid + hat_width / 2.), hat_level, base_level)\n",
    "\n",
    "\n",
    "def objective(params, x, y):\n",
    "\treturn np.sum(np.abs(tophat(x, *params) - y))\n",
    "\n",
    "\n",
    "def find_center_of_spot(y, x, qry_eval):\n",
    "\t# input:\n",
    "\t#  y: gaussian fit values along y (x=0)\n",
    "\t#  x: corresponding x values\n",
    "\t#  qry_eval: query points for the vertical and horizontal line\n",
    "\n",
    "\tidx_max = np.argmax(y)\n",
    "\tx_at_max = x[idx_max]\n",
    "\n",
    "\tidx_centerline_x = (np.abs(qry_eval - x_at_max)).argmin()\n",
    "\t# print(x_at_max)\n",
    "\treturn x_at_max, idx_centerline_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing file 02.MR.102.particleData.csv\n",
      "100.0% of the initial 1000 particles have arrived at the target (x > 10.0 mm and x < 90.0 mm).\n",
      "Creating plot for time time t=2.5E-7 s\n",
      "Doing file 02.MR.106.particleData.csv\n",
      "100.0% of the initial 1000 particles have arrived at the target (x > 10.0 mm and x < 90.0 mm).\n",
      "Creating plot for time time t=2.5E-7 s\n",
      "Doing file 02.MR.103.particleData.csv\n",
      "100.0% of the initial 1000 particles have arrived at the target (x > 10.0 mm and x < 90.0 mm).\n",
      "Creating plot for time time t=2.5E-7 s\n",
      "Doing file 02.MR.104.particleData.csv\n",
      "100.0% of the initial 1000 particles have arrived at the target (x > 10.0 mm and x < 90.0 mm).\n",
      "Creating plot for time time t=2.5E-7 s\n",
      "Doing file 02.MR.101.particleData.csv\n",
      "100.0% of the initial 1000 particles have arrived at the target (x > 10.0 mm and x < 90.0 mm).\n",
      "Creating plot for time time t=2.5E-7 s\n",
      "Doing file 02.MR.105.particleData.csv\n",
      "100.0% of the initial 1000 particles have arrived at the target (x > 10.0 mm and x < 90.0 mm).\n",
      "Creating plot for time time t=2.5E-7 s\n"
     ]
    }
   ],
   "source": [
    "COMSOL_data_file_path = remote_path\n",
    "\n",
    "COMSOL_files = os.listdir(COMSOL_data_file_path)\n",
    "# COMSOL_files = [f for f in COMSOL_files if 'particleData' in f]\n",
    "COMSOL_files = [f for f in COMSOL_files if f.endswith('.csv')]\n",
    "COMSOL_files = [f'{COMSOL_data_file_path}{f}' for f in COMSOL_files]\n",
    "\n",
    "df_output = pd.DataFrame()\n",
    "for COMSOL_data_file in COMSOL_files:\n",
    "\n",
    "\trunfile = re.findall(r'[^/]+(?=/$|$)', COMSOL_data_file)[0]\n",
    "\tprint(f'Doing file {runfile}')\n",
    "\t# import the particle data file\n",
    "\tdf = pd.read_csv(COMSOL_data_file, skiprows=8, header=None)\n",
    "\tdf_FWHM = pd.DataFrame()  # this is the output dataframe that contains the FWHM\n",
    "\t# find column headers\n",
    "\tc = []\n",
    "\twith open(COMSOL_data_file, 'r') as myfile:\n",
    "\t\tfor line in myfile:\n",
    "\t\t\tif 'Index' in line:\n",
    "\t\t\t\tl = line.rstrip().split(',')\n",
    "\t\t\t\tc.append(l)\n",
    "\n",
    "\tmyfile.close()\n",
    "\tcols = c[0]\n",
    "\t# print(c)\n",
    "\t# get the time stepping\n",
    "\t# extract t=... from the cols\n",
    "\tmy_cols = []\n",
    "\tfor ii in range(0,len(cols)):\n",
    "\t\tcol = cols[ii]\n",
    "\n",
    "\t\tt0 = re.findall(r'(t=.*)', col)\n",
    "\t\tif len(t0) > 0:\n",
    "\t\t\tmy_cols.append(t0[0])\n",
    "\t\telse:\n",
    "\t\t\tmy_cols.append('noTimestamp')\n",
    "\n",
    "\t# timeStep = my_cols[4]\n",
    "\ttime_cols = (pd.Series(item for item in my_cols)).unique()[1:] # drop the timestamp\n",
    "\n",
    "\t#set column header of df\n",
    "\tcols[0] = 'particleindex'\n",
    "\tdf.columns = cols\n",
    "\n",
    "\t# check which particles have arrived at the target\n",
    "\t# get the latest timestamp\n",
    "\tdf_last = df.filter(regex=time_cols[-1], axis=1)\n",
    "\n",
    "\t# length: total number of particles\n",
    "\tn_total = len(df_last)\n",
    "\n",
    "\t# only those particles that have made it to the target: 10 mm in +x direction\n",
    "\t# for dist in [1,5,10,80]:\n",
    "\tdist_min = 10.0\n",
    "\tdist_max = 90.0  # needs to be adjusted for the 10.run\n",
    "\tdf_arrived = df_last[ (df_last.iloc[:,0] > dist_min) &(df_last.iloc[:,0] < dist_max) ]\n",
    "\tn_arrived = len(df_arrived)\n",
    "\t# print(df_last)\n",
    "\t# print(df_last)\n",
    "\t# percent of those that have arrived\n",
    "\tperc_arrived = round((n_arrived / n_total)*100.0,2)\n",
    "\n",
    "\tprint('{}% of the initial {} particles have arrived at the target (x > {} mm and x < {} mm).'.format(perc_arrived, n_total, dist_min, dist_max))\n",
    "\tif perc_arrived < 10:\n",
    "\t\tprint('{}% smaller than 10 %, avoid this file).'.format(perc_arrived))\n",
    "\t\tcontinue\n",
    "\t# print(df.head())\n",
    "\t# print(sys.exit())\n",
    "\t# index of the particle that have arrived at the target\n",
    "\tidx_arrived = df_arrived.index.tolist()\n",
    "\n",
    "\n",
    "\t# select only the last timestep\n",
    "\tthis_df = df.filter(regex=time_cols[-1], axis=1)\n",
    "\n",
    "\t# compute beam radius\n",
    "\n",
    "\tthis_df = this_df.iloc[idx_arrived,:]\n",
    "\n",
    "\tqy = this_df.iloc[:,1]\n",
    "\tqz = this_df.iloc[:,2]\n",
    "\n",
    "\tfname = re.findall(r'/([\\w.]+).csv',COMSOL_data_file)[0]\n",
    "\t# print(fname)\n",
    "\tdirectory = '{}/plots/2D_histograms_lastTimestep'.format(COMSOL_data_file_path,fname)\n",
    "\tif not os.path.exists(directory):\n",
    "\t\tos.makedirs(directory)\n",
    "\n",
    "\n",
    "\tmytime = time_cols[-1]\n",
    "\tprint('Creating plot for time time {} s'.format(mytime))\n",
    "\t# select only the last timestep\n",
    "\tthis_df = df.filter(regex=mytime, axis=1)\n",
    "\n",
    "\t# compute beam radius\n",
    "\n",
    "\tthis_df = this_df.iloc[idx_arrived,:]\n",
    "\tqx = this_df.iloc[:,0]\n",
    "\tmedian_qx = np.median(qx)\n",
    "\tqy = this_df.iloc[:,1]\n",
    "\tqz = this_df.iloc[:,2]\n",
    "\tqr = np.sqrt(qy**2+qz**2)\n",
    "\n",
    "\tnbins = 200\n",
    "\tlim = 3\n",
    "\tx = qy\n",
    "\ty = qz\n",
    "\tdata = np.vstack([qy, qz])\n",
    "\tk = kde.gaussian_kde(data)\n",
    "\t# xi, yi = np.mgrid[x.min():x.max():nbins*1j, y.min():y.max():nbins*1j]\n",
    "\txi, yi = np.mgrid[-3:3:nbins*1j, -3:3:nbins*1j]\n",
    "\tzi = k(np.vstack([xi.flatten(), yi.flatten()]))\n",
    "\tdf_histData = pd.DataFrame()\n",
    "\n",
    "\tdf_histData['qx'] = qx\n",
    "\tdf_histData['qy'] = qy\n",
    "\tdf_histData['qz'] = qz\n",
    "\n",
    "\t# compute FWHM for all points parallel to the x and y axis\n",
    "\tqry_eval = np.linspace(-lim, lim, 100)\n",
    "\ty_values = [k.evaluate([0, y])[0] for y in qry_eval]\n",
    "\n",
    "\teval_y = y_values\n",
    "\n",
    "\n",
    "\t# print(kint)\n",
    "\tdf_res = pd.DataFrame()\n",
    "\tdf_res['qry_eval'] = qry_eval\n",
    "\tdf_res['eval_y'] = eval_y\n",
    "\n",
    "\t# fit FWHM\n",
    "\t# Create a function which returns a Gaussian (normal) distribution.\n",
    "\tdef gauss(p, x):\n",
    "\t\ta, b, c, d = p\n",
    "\t\ty = a*np.exp(-np.power((x - b), 2.)/(2. * c**2.)) + d\n",
    "\t\treturn y\n",
    "\tdef errfunc(p, x, y):\n",
    "\t\treturn gauss(p, x) - y # Distance to the fit function\n",
    "\n",
    "\tp0 = [1, 1, 1, 1] # Initial guess for the parameters\n",
    "\n",
    "\t# fit for parallel to y axis\n",
    "\tX_f = qry_eval\n",
    "\tY_f = eval_y\n",
    "\t# print(df.norm_cps)\n",
    "\t# print(X_f, Y_f)\n",
    "\tp1, success = optimize.leastsq(errfunc, p0[:], args=(X_f, Y_f))\n",
    "\tY_fit = gauss(p1, X_f)\n",
    "\t# save df to csv\n",
    "\tdf_FWHM_y = pd.DataFrame(X_f, columns=['X_fit'])\n",
    "\tdf_FWHM_y['Y_fit'] = Y_fit\n",
    "\tdf_FWHM_y['sigma'] = p1[2]  # sigma in gaussian\n",
    "\tdf_FWHM_y['FWHM'] = 2.08 * p1[2] * np.sqrt(2 * np.log(2))  # FWHM\n",
    "\t# fname = f'{master_folder}/df_FWHM_y.csv'\n",
    "\t# df_FWHM_y.to_csv(fname)\n",
    "\tdf_FWHM['FWHM_y'] = df_FWHM_y['FWHM'].unique()\n",
    "\n",
    "\n",
    "\t# find maximum position of gaussian fit along y\n",
    "\t# to find center of 03_BeamOptics\n",
    "\tval_x, qry_x = find_center_of_spot(df_FWHM_y['Y_fit'].values,\n",
    "\t\t\t\t\t\t\t\tdf_FWHM_y['X_fit'].values,\n",
    "\t\t\t\t\t\t\t\tqry_eval)\n",
    "\n",
    "\t# print(qry_x)\n",
    "\t# sys.exit()\n",
    "\t# qry_eval = np.linspace(-lim, lim, 100)\n",
    "\teval_x = [k.evaluate([x, val_x])[0] for x in qry_eval]\n",
    "\t# print(eval_x)\n",
    "\tdf_res['eval_x'] = eval_x\n",
    "\t# fit for parallel to x axis\n",
    "\tX_f = qry_eval\n",
    "\tY_f = eval_x\n",
    "\t# print(df.norm_cps)\n",
    "\t# print(X_f, Y_f)\n",
    "\tp1, success = optimize.leastsq(errfunc, p0[:], args=(X_f, Y_f), maxfev=100000)\n",
    "\tY_fit = gauss(p1, X_f)\n",
    "\t# save df to csv\n",
    "\tdf_FWHM_x = pd.DataFrame(X_f, columns=['X_fit'])\n",
    "\tdf_FWHM_x['Y_fit'] = Y_fit\n",
    "\tdf_FWHM_x['sigma'] = p1[2]  # sigma in gaussian\n",
    "\tdf_FWHM_x['FWHM'] = 2.08 * p1[2] * np.sqrt(2 * np.log(2))  # FWHM\n",
    "\t# fname = f'{master_folder}/df_FWHM_x.csv'\n",
    "\t# df_FWHM_x.to_csv(fname)\n",
    "\tdf_FWHM['FWHM_x'] = df_FWHM_x['FWHM'].unique()\n",
    "\n",
    "\tdf_FWHM['FWHM'] = (np.abs(df_FWHM['FWHM_y']) +\n",
    "\t\t\t\t\t\tnp.abs(df_FWHM['FWHM_x'])) / 2.0\n",
    "\n",
    "\t# plt.plot(X_f, eval_x)\n",
    "\t# plt.show()\n",
    "\t# sys.exit()\n",
    "\n",
    "\t# tophat\n",
    "\ttophat_params = [ [0, 0, 0, 0], [0, 0, 0, 0] ]  # x, y\n",
    "\tfor eval, mode in zip([eval_x, eval_y], ['hat_x_width', 'hat_y_width']):\n",
    "\t\tguess = [0, 0.3, 0, 2] # (base_level, hat_level, hat_mid, hat_width)\n",
    "\t\tres = minimize(objective, guess, args=(X_f, eval),\n",
    "\t\t\tmethod='Nelder-Mead',\n",
    "\t\t\toptions={'maxfev': 10000000})\n",
    "\t\t# plt.plot(X_f, tophat(X_f, *(res.x)))\n",
    "\t\tdf_FWHM[mode] = res.x[3]\n",
    "\t\tif mode == 'hat_x_width':\n",
    "\t\t\ttophat_params[0] = res.x\n",
    "\t\telse:\n",
    "\t\t\ttophat_params[1] = res.x\n",
    "\n",
    "\n",
    "\n",
    "\tf = plt.figure(1, figsize=(7.5, 7.5))\n",
    "\n",
    "\tnullfmt = NullFormatter()         # no labels\n",
    "\n",
    "\t# definitions for the axes\n",
    "\tleft, width = 0.10, 0.6\n",
    "\tbottom, height = 0.10, 0.6\n",
    "\tbottom_h = left_h = left + width + 0.02\n",
    "\n",
    "\trect_scatter = [left, bottom, width, height]\n",
    "\trect_histx = [left, bottom_h, width, 0.2]\n",
    "\trect_histy = [left_h, bottom, 0.2, height]\n",
    "\n",
    "\taxScatter = plt.axes(rect_scatter)\n",
    "\n",
    "\taxHistx = plt.axes(rect_histx)\n",
    "\tplt.title(f'{runfile}')\n",
    "\taxHisty = plt.axes(rect_histy)\n",
    "\n",
    "\t# no labels\n",
    "\taxHistx.xaxis.set_major_formatter(nullfmt)\n",
    "\taxHisty.yaxis.set_major_formatter(nullfmt)\n",
    "\taxHistx.grid(True)\n",
    "\taxHisty.grid(True)\n",
    "\n",
    "\n",
    "\tp = axScatter.pcolormesh(xi, yi, zi.reshape(xi.shape), shading='gouraud', cmap=plt.cm.jet)\n",
    "\taxScatter.set_xlabel('y [mm]')\n",
    "\taxScatter.set_ylabel('z [mm]')\n",
    "\n",
    "\t# contours = axScatter.contour(xi, yi, zi.reshape(xi.shape), cmap=plt.cm.Blues, levels=[my_lvl])\n",
    "\t# plt.clabel(contours, inline=True, fontsize=8)\n",
    "\taxScatter.set_facecolor('#000080ff')\n",
    "\tplt.colorbar(p)\n",
    "\n",
    "\t# compute FWHM for all x and y histograms\n",
    "\t# select the largest FWHM\n",
    "\n",
    "\taxScatter.set_xlim((-lim, lim))\n",
    "\taxScatter.set_ylim((-lim, lim))\n",
    "\n",
    "\t# left = 0.8\n",
    "\t# bottom = 0.12\n",
    "\t# width = 0.05\n",
    "\t# height = 0.65\n",
    "\t#\n",
    "\t# cax = f.add_axes([left, bottom, width, height])\n",
    "\t# cbar = f.colorbar(p, cax)\n",
    "\t#\n",
    "\t# cbar.ax.tick_params(labelsize=12)\n",
    "\t#\n",
    "\t# plt.subplots_adjust(left=None, bottom=0.2, right=None, top=0.68,\n",
    "\t# \twspace=None, hspace=0.2)\n",
    "\n",
    "\t# compute FWHM for all points parallel to the x and y axis\n",
    "\t# qry_eval = np.linspace(-lim,lim,100)\n",
    "\t# eval_x = [k.evaluate([x,0])[0] for x in qry_eval]\n",
    "\t# eval_y = [k.evaluate([0,y])[0] for y in qry_eval]\n",
    "\n",
    "\t# # print(kint)\n",
    "\t# #\n",
    "\t# df_res = pd.DataFrame()\n",
    "\t# df_res['qry_eval'] = qry_eval\n",
    "\t# df_res['eval_x'] = eval_x\n",
    "\t# df_res['eval_y'] = eval_y\n",
    "\t# # df_res['kint_1'] = kint\n",
    "\t# df_res['type_file'] = type_file\n",
    "\t# # df_res['contour_level'] = my_lvl\n",
    "\t# fwhm_x = calculateFWHM(qry_eval,df_res['eval_x'])\n",
    "\t# fwhm_y = calculateFWHM(qry_eval,df_res['eval_y'])\n",
    "\n",
    "\n",
    "\t# first of all, the base transformation of the data points is needed\n",
    "\tbase = pyplot.gca().transData\n",
    "\trot = transforms.Affine2D().rotate_deg(270)\n",
    "\taxScatter.plot([-lim, lim], [val_x, val_x], color='black', linestyle='dashed')\n",
    "\taxScatter.plot([0, 0], [-lim, lim], color='black')\n",
    "\tplt.axis('equal')\n",
    "\t# print(tophat_params)\n",
    "\taxHistx.plot(df_res['qry_eval'].values, df_res['eval_x'], c='black', linestyle='dashed')\n",
    "\taxHistx.plot(df_FWHM_x['X_fit'], df_FWHM_x['Y_fit'], c='red', linestyle='dotted')\n",
    "\taxHistx.plot(df_FWHM_x['X_fit'], tophat(df_FWHM_x['X_fit'], *(tophat_params[0])), c='green', linestyle='dotted')\n",
    "\taxHisty.plot(df_res['qry_eval'].values, df_res['eval_y'].values[::-1], c='black', transform= rot + base)\n",
    "\taxHisty.plot(df_FWHM_y['X_fit'], df_FWHM_y['Y_fit'].values[::-1], c='red', linestyle='dotted', transform= rot + base)\n",
    "\t# axHisty.plot(df_FWHM_y['X_fit'], tophat(df_FWHM_y['X_fit'], *(tophat_params[1]))[::-1], c='green', linestyle='dotted', transform= rot + base)\n",
    "\n",
    "\n",
    "\taxHistx.set_xlim(axScatter.get_xlim())\n",
    "\taxHisty.set_ylim(axScatter.get_ylim())\n",
    "\n",
    "\t# f.tight_layout()\n",
    "\t# df_x_FWHM, df_y_FWHM = getLargestFWHM(k, lim)\n",
    "\n",
    "\t# df_x_FWHM.to_csv('{}/df_x_FWHM.csv'.format(directory))\n",
    "\t# df_y_FWHM.to_csv('{}/df_y_FWHM.csv'.format(directory))\n",
    "\n",
    "\t# plt.show()\n",
    "\n",
    "\tfilename =  '{}/{}'.format(directory, runfile)\n",
    "\tdf_histData.to_csv(f'{filename}_df_histData.csv')\n",
    "\t# print(nn)\n",
    "\t# plt.savefig(filename + '.eps', dpi=1200)\n",
    "\t# plt.savefig(filename + '.svg', dpi=1200)\n",
    "\tplt.savefig(filename + '.png', dpi=600)\n",
    "\n",
    "\tplt.close('all')\n",
    "\tif 'BIDIR' in runfile:\n",
    "\t\ts_type = 'BIDIR'\n",
    "\telse:\n",
    "\t\ts_type = 'TD'\n",
    "\t# id = re.findall(r'(\\d\\d)\\.', runfile)[0]\n",
    "\tdf_FWHM['id'] = runfile\n",
    "\tdf_FWHM['runfile'] = runfile\n",
    "\tdf_FWHM['run_type'] = s_type\n",
    "\tdf_output = df_output.append(df_FWHM)\n",
    "\t# plt.show()\n",
    "\n",
    "fname = f'{COMSOL_data_file_path}/plots/2D_histograms_lastTimestep/df_FWHMs.csv'\n",
    "df_output.to_csv(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
