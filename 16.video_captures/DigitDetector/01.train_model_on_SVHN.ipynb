{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make this class importable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "class SVHNDataset():\n",
    "    \n",
    "    def load_dataset(self, path_train, path_test):\n",
    "        \"\"\"\n",
    "        Loads the .mat file from the SVHN Dataset (train and test) indicated at location path. Returns it as numpy array,\n",
    "        \"\"\"\n",
    "        train_dataset = sio.loadmat(path_train)\n",
    "        test_dataset = sio.loadmat(path_test)\n",
    "\n",
    "        train_data, train_labels = train_dataset['X'], train_dataset['y']\n",
    "        test_data, test_labels = test_dataset['X'], test_dataset['y']\n",
    "\n",
    "        print( 'Train data:', train_data.shape,', Train labels:', train_labels.shape )\n",
    "        print( 'Test data:', test_data.shape,', Test labels:', test_labels.shape )\n",
    "        \n",
    "        return train_data, train_labels, test_data, test_labels\n",
    "    \n",
    "    def convert_to_gray(self, data):\n",
    "        \"\"\"\n",
    "        Converts all the images in the dataset into gray scale. Returns the dataset with grayscale entries.\n",
    "        \"\"\"\n",
    "        \n",
    "        r, g, b = data[:,:,0,:], data[:,:,1,:], data[:,:,2,:]\n",
    "        gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "        data[:,:,0,:] = gray\n",
    "        data = data[:,:,0,:]\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def preprocess_for_KERAS_reshaping(self, framesize, dataset):        \n",
    "        \"\"\"\n",
    "        Preprocessing for the dataset to be used in KERAS.\n",
    "        INPUT:\n",
    "            - dataset: numpy array with shape (framesize, framesize, #examples). Should be\n",
    "                        after the grayscaling step!\n",
    "            - framesize: number that depicts the size of the frame, i.e. 32x32\n",
    "        OUTPUT:\n",
    "            - dataset that is still a numpy array. Shape is (#examples, framesize, framesize, 1)\n",
    "        \"\"\"\n",
    "        dataset = np.rollaxis(dataset,2)\n",
    "\n",
    "\n",
    "        dataset = dataset.reshape(-1, framesize, framesize, 1)\n",
    "\n",
    "#         print(f'Dataset reshaped to: {dataset.shape}')\n",
    "    \n",
    "        return dataset\n",
    "    \n",
    "    \n",
    "    def preprocess_for_KERAS_labels(self, labels_dataset):        \n",
    "        \"\"\"\n",
    "        Preprocessing for the labels of dataset to be used in KERAS. Converts 10 to 0, and reshapes.\n",
    "        INPUT:\n",
    "            - labels_dataset: numpy array with shape (#examples,1). \n",
    "        OUTPUT:\n",
    "            - labels_dataset that is still a numpy array. Shape is (#examples,). 10 is replaced with 0\n",
    "        \"\"\"\n",
    "        labels_dataset = labels_dataset[:,0]\n",
    "        labels_dataset[labels_dataset==10] = 0\n",
    "        \n",
    "        return labels_dataset\n",
    "\n",
    "    \n",
    "    def model_definition(self):\n",
    "        \"\"\"\n",
    "        Builds the model for the digit detection. \n",
    "        Taken from https://nbviewer.jupyter.org/github/dyckia/SVHN-CNN/blob/master/SVHN.ipynb.\n",
    "        \"\"\"\n",
    "\n",
    "        model = Sequential([\n",
    "            Conv2D(32, (3,3), activation='relu', input_shape=(32,32,1)),\n",
    "            Conv2D(32, (3,3), activation='relu'),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Dropout(0.3),\n",
    "            Conv2D(64, (3,3), activation='relu'),\n",
    "            Conv2D(64, (3,3), activation='relu'),\n",
    "            MaxPooling2D(2, 2),\n",
    "            Dropout(0.3),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "\n",
    "        # get a summary of our built model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (32, 32, 3, 73257) , Train labels: (73257, 1)\n",
      "Test data: (32, 32, 3, 26032) , Test labels: (26032, 1)\n",
      " \n",
      "After conversion to grayscale: \n",
      "Train data: (32, 32, 73257), labels: (73257, 1)\n",
      "Test data: (32, 32, 26032), labels: (26032, 1)\n",
      " \n",
      "After preprocessing reshaping: \n",
      "X_train data: (73257, 32, 32, 1)\n",
      "X_test data: (26032, 32, 32, 1)\n",
      " \n",
      "After preprocessing labels: \n",
      "Train labels: (73257,)\n",
      "Test  labels: (26032,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 889,834\n",
      "Trainable params: 889,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "svhn = SVHNDataset()\n",
    "path_train  = '/Users/hkromer/02_PhD/02_Data/12.dcr/Stanford_housenumbers/train_32x32.mat'\n",
    "path_test  = '/Users/hkromer/02_PhD/02_Data/12.dcr/Stanford_housenumbers/test_32x32.mat'\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = svhn.load_dataset(path_train, path_test)\n",
    "# convert to grayscale\n",
    "train_data = svhn.convert_to_gray(train_data)\n",
    "test_data = svhn.convert_to_gray(test_data)\n",
    "print(' ')\n",
    "print('After conversion to grayscale: ')\n",
    "print(f'Train data: {train_data.shape}, labels: {train_labels.shape}')\n",
    "print(f'Test data: {test_data.shape}, labels: {test_labels.shape}')\n",
    "\n",
    "X_train = svhn.preprocess_for_KERAS_reshaping(32, train_data)\n",
    "X_test = svhn.preprocess_for_KERAS_reshaping(32, test_data)\n",
    "print(' ')\n",
    "print('After preprocessing reshaping: ')\n",
    "print(f'X_train data: {X_train.shape}')\n",
    "print(f'X_test data: {X_test.shape}')\n",
    "\n",
    "y_train = svhn.preprocess_for_KERAS_labels(train_labels)\n",
    "y_test = svhn.preprocess_for_KERAS_labels(test_labels)\n",
    "print(' ')\n",
    "print('After preprocessing labels: ')\n",
    "print(f'Train labels: {y_train.shape}')\n",
    "print(f'Test  labels: {y_test.shape}')\n",
    "\n",
    "\n",
    "model = svhn.model_definition()\n",
    "\n",
    "# define the optimizer, loss function and metrics for the network\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# start training\n",
    "history = model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
